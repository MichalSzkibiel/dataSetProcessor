{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8916fa-1f8d-4d0d-8681-ebb946efc18a",
   "metadata": {},
   "source": [
    "# Example workflow\n",
    "This notebook shows example workflow for dataSetProcessor.\n",
    "## Images\n",
    "First we need an image in a given scope for what we will use find_sentinel2.\n",
    "\n",
    "### Copernicus authentication\n",
    "You need to open config.py and fill in your user data in \"copernicus_token_data\"\n",
    "\n",
    "### Workspace\n",
    "By default workspace is created in directory where it is installed. To change it, pass absolute path to \"workspace\" parameter in config.py\n",
    "\n",
    "### Searching images\n",
    "To find images we will use find_sentinel2 function. This has given parameters:\\\n",
    "    1. start_date - datetime from which we will search\\\n",
    "    2. end_date - datetime to which we will search\\\n",
    "    3. bbox - bounding box in \"EPSG:4326\" in order left, bottom, right, top\\\n",
    "    4. products - list of products. It may contain 'L1C' or 'L2A' or both\\\n",
    "    5. cloud_cover - highest percentage of cloud cover\\\n",
    "The output is a metadata of found images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d2294c9-aa05-4c07-b4ed-4fee857bed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_MSIL1C_20230910T100601_N0509_R022_T33UVV_20230910T135051.SAFE\n",
      "S2A_MSIL2A_20230910T100601_N0509_R022_T33UVV_20230910T161500.SAFE\n"
     ]
    }
   ],
   "source": [
    "from bbox import Bbox\n",
    "from image import find_sentinel2\n",
    "import datetime\n",
    "found = find_sentinel2(\n",
    "        datetime.datetime(2023, 9, 10, 0, 0, 0),\n",
    "        datetime.datetime(2023, 9, 11, 23, 59, 59),\n",
    "        bbox=Bbox(\n",
    "            14.8,\n",
    "            53.5,\n",
    "            14.9,\n",
    "            53.6,\n",
    "            \"EPSG:4326\"\n",
    "        ),\n",
    "        products=['L1C', 'L2A'],\n",
    "        cloud_cover=30\n",
    "    )\n",
    "for el in found:\n",
    "    print(el.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceb45bc-2c2b-4c54-930d-1e96a3d3cbe5",
   "metadata": {},
   "source": [
    "### Saving images\n",
    "To keep this metadata in directory we should use save function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e128e7-0186-48b3-87fb-06f6ce7b4a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in found:\n",
    "    el.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd72f0b-7c20-4223-b6b6-af804f1d6c30",
   "metadata": {},
   "source": [
    "### Cloud masks\n",
    "\n",
    "DataSetProcessor can detect clouds and cirruses using IDEPIX Sentinel-2 algorithm - which is implemented in Python. Function creates 60 meters cloud mask for a L1C image with parameters:\n",
    "1. buffer_size - indicating queen (8 connected) distance from clouds, meaning to which extent cloud mask should be widened.\n",
    "2. dem_path - path to digital elevation model (DEM) covering the image with approbiate CRS and 60m pixel aligned to scene. DEM for this example is in the repository under path \"dems/srtm.tif\"\n",
    "\n",
    "The output is a combined mask, where:\\\n",
    "(output & 8) == 1 are cloud sure,\\\n",
    "(output & 4) == 1 are cloud ambigous,\\\n",
    "(output & 2) == 1 are cirrus sure,\\\n",
    "(output & 1) == 1 are cirrus ambigous\\\n",
    "The mask will be saved to cloud_masks directory with name of a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7dda59-45e9-411a-aed9-f0d32b1a9311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B01.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B02.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B03.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B04.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B05.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B06.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B07.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B08.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B09.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B10.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B11.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B12.jp2\n",
      "C:\\Users\\trole\\Documents\\dataSetProcessorWorkspace\\temp\\2939f355-a84b-4407-acb6-da49657d6bac\\T33UVV_20230910T100601_B8A.jp2\n"
     ]
    }
   ],
   "source": [
    "for el in found:\n",
    "    if 'L1C' in el.name:\n",
    "        el.get_cloud_mask(2, \"dems/srtm.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d11fb3-b070-467a-affb-894124ca80ec",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "### Vector Dataset\n",
    "Now we can generate dataset on found scene. We will use a dataset from examples as a label data. To make a dataset we will use class VectorDataset. The constructor takes parameters:\n",
    "1. dataset_name - the name under which the dataset will be saved\n",
    "2. label_source - GeoDataFrame with polygons serving as labels\n",
    "3. class_column - the name of column with classes as integers\n",
    "4. sentinel2image - list of image objects to take picture data. It's designed to take L2A images\n",
    "5. apply_cloud_mask - list of cloud_mask layers to exclude pixels. The meaning of integers is given above\n",
    "6. window_size - radius of processing window. If you take 0, it will be the pixel only. For n it will be 2*n+1 x 2*n+1 square with labeled pixel in the middle\n",
    "7. is_conv - whether to prepare the dataset to be served by convolutional neural networks. If True, it keeps the shape of parameters: 10 x 2*n+1 x 2*n+1. Otherwise they're flattened\n",
    "8. apply_rotations_and_reflections - if True, it performs data augmentation by adding to dataset rotations and reflections of rotations resulting in increasing of dataset 8 times. If window_size=0 it only repeats every feature 8 times and does not give any real additional features\n",
    "\n",
    "dataset.save_dataset() saves dataset to directory \"datasets\". It also writes docx report to \"reports/dataset\" under the same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45c6a7fe-00e4-47fc-acd0-bb8c7fea753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    klasa                                           geometry\n",
      "0       0  POLYGON ((476941.315 5934303.877, 476935.787 5...\n",
      "1       0  POLYGON ((489648.891 5935665.666, 489794.468 5...\n",
      "2       0  POLYGON ((500283.378 5933406.460, 500209.668 5...\n",
      "3       0  POLYGON ((497747.759 5933175.195, 497891.494 5...\n",
      "4       1  POLYGON ((489860.807 5935099.943, 489693.318 5...\n",
      "..    ...                                                ...\n",
      "91      3  POLYGON ((493656.920 5932403.273, 493616.878 5...\n",
      "92      3  POLYGON ((498117.435 5937455.194, 498239.190 5...\n",
      "93      3  POLYGON ((497782.235 5937095.943, 497956.599 5...\n",
      "94      3  POLYGON ((492720.158 5933242.893, 492876.485 5...\n",
      "95      3  POLYGON ((492720.158 5933511.454, 492635.982 5...\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "['T33UVV_20230910T100601_B02_10m.jp2', 'T33UVV_20230910T100601_B03_10m.jp2', 'T33UVV_20230910T100601_B04_10m.jp2', 'T33UVV_20230910T100601_B05_20m.jp2', 'T33UVV_20230910T100601_B06_20m.jp2', 'T33UVV_20230910T100601_B07_20m.jp2', 'T33UVV_20230910T100601_B08_10m.jp2', 'T33UVV_20230910T100601_B11_20m.jp2', 'T33UVV_20230910T100601_B12_20m.jp2', 'T33UVV_20230910T100601_B8A_20m.jp2']\n",
      "{0, 1, 2, 3, 4}\n",
      "(251856,)\n",
      "(251856, 10, 1, 1)\n",
      "(251856, 10)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from dataset import VectorDataset\n",
    "from image import load_image\n",
    "\n",
    "data = gpd.read_file('examples/pokrycie2.shp')\n",
    "print(data)\n",
    "\n",
    "dataset = VectorDataset(\n",
    "        dataset_name=\"goleniow1\",\n",
    "        label_source=data,\n",
    "        class_column=\"klasa\",\n",
    "        sentinel2image=[load_image(\"S2A_MSIL2A_20230910T100601_N0509_R022_T33UVV_20230910T161500.SAFE\")],\n",
    "        apply_cloud_mask=[8, 4],\n",
    "        window_size=0,\n",
    "        is_conv=False,\n",
    "        apply_rotations_and_reflections=False\n",
    "    )\n",
    "dataset.save_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5287e640-d4f9-44db-98cd-d2d81c4a1afc",
   "metadata": {},
   "source": [
    "### Partial Dataset\n",
    "To extract part of features to make dataset equally distributed in classes, code below runs it. Count variable indicates how many objects of one class should be in partial dataset. The partial dataset will be saved to directory \"datasets/{name of full dataset}\" as \"{count}\" and report docx to directory \"reports/datasets/{name of full dataset}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07426767-526f-490a-83bb-fd0fffc942ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3750, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset import PartialDataset\n",
    "\n",
    "indices = np.arange(len(dataset.labels))\n",
    "labels_indices = {el: indices[dataset.labels == el] for el in set(dataset.labels)}\n",
    "\n",
    "for label in labels_indices:\n",
    "    np.random.shuffle(labels_indices[label])\n",
    "\n",
    "count = 750\n",
    "\n",
    "part_features = []\n",
    "part_labels = []\n",
    "for label in labels_indices:\n",
    "    part_features += dataset.features[labels_indices[label][:count]].tolist()\n",
    "    part_labels += [label] * count\n",
    "\n",
    "PartialDataset(\n",
    "    dataset=dataset,\n",
    "    subset_id=f\"{count}\",\n",
    "    features=np.array(part_features),\n",
    "    labels=np.array(part_labels)\n",
    ").save_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e358c0-8556-4ab2-8b47-fa4e8d2e1ca5",
   "metadata": {},
   "source": [
    "## Learning models\n",
    "### Defining model\n",
    "Now we will define model on which data will be trained. Parameters are:\n",
    "1. name - shows the name under which the model will be saved.\n",
    "2. classifier - function initializing classifying algorithm. In example is passed function initializing random forest classifier with 150 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a96ea2a-3a75-4345-a438-268f7ee94cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "from functools import partial\n",
    "\n",
    "m = model.Model(\n",
    "    name=\"rfc150\",\n",
    "    classifier=partial(\n",
    "        model.random_forest,\n",
    "        n_estimators=150\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71ab49-0ab2-4e06-bee8-690ca6339e2e",
   "metadata": {},
   "source": [
    "### Learning\n",
    "To learn will be used function learn with parameters:\n",
    "1. dataset_name - the name dataset to be trained on. To choose partial dataset indicate \"{dataset_name}_parts/{subset_id}\"\n",
    "2. report_name - the name of docx report saved to \"reports/learning\" directory\n",
    "3. test_size - the size of validation dataset from 0 to 1. Indicate 0 if you don't want validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7362c73d-be44-438f-a6f0-5e5d509a8a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7626666666666667, 0.702433359560805)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.learn(\"goleniow1_parts/750\", \"goleniow1_rfc150\", test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e1c96-f9e9-4572-8608-40fc2d638bcd",
   "metadata": {},
   "source": [
    "## Test dataset\n",
    "### Classified image\n",
    "Now we have learned model and we want to create test dataset in random points with comparable number of features in different classess. So first we need a classified image. To create classified image we will use \"classify_image\" function with parameters:\n",
    "1. image_name - name of image to be classified\n",
    "2. output_file - name of ouput file saved to directory \"classImages\"\n",
    "3. bbox - bbox of area in which we want do the classification. Indicate None if you want to classify whole image\n",
    "4. apply_cloud_mask - indicate which layers of cloud mask overrides predictions of a model and sets it to invalid. Indicate None to skip, defaults to None\n",
    "5. invalid_value - value of pixels which are considered invalid after applying cloud mask, defaults to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e1f495f-06a4-4eb1-bf94-3dfa6d4fab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.classify_image(\n",
    "    \"S2A_MSIL2A_20230910T100601_N0509_R022_T33UVV_20230910T161500.SAFE\",\n",
    "    \"RFC150\",\n",
    "    Bbox(\n",
    "        53.82,\n",
    "        14.0324,\n",
    "        54.1,\n",
    "        14.25,\n",
    "        \"EPSG:4326\"\n",
    "    ),\n",
    "    apply_cloud_mask=(8,4),\n",
    "    invalid_value=255\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f06474a-2cb2-4ad5-8241-add7954f1aa6",
   "metadata": {},
   "source": [
    "### Creating test dataset\n",
    "Now we choose pixels on classified image. It is made by create_test_dataset function with parameters:\n",
    "1. dataset_name - name of dataset under which it will be saved to directory \"test_datasets\"\n",
    "2. class_raster - the path to classiffied image\n",
    "3. bbox - bounding box of a dataset. Indicate None to take data from whole image\n",
    "4. mode - mode of creating dataset. It has three possible values:\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;a. \"total_random\" - every pixel will be chosen with the same propability\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;b. \"proportional\" - mode to preserve propotions between classes\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;c. \"equal\" - mode in which every class will be represented by the same amount of pixels\n",
    "5. count - final size of the dataset\n",
    "6. included_values - values that represent classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abd4d2b6-b6a0-494f-af8e-34cd9c7ea764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import create_test_dataset\n",
    "\n",
    "create_test_dataset(\n",
    "    dataset_name=\"Swinoujscie\",\n",
    "    class_raster=\"classImages/RFC150.tif\",\n",
    "    bbox=None,\n",
    "    mode=\"equal\",\n",
    "    count=500,\n",
    "    included_values=[0,1,2,3,4]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c6363-31ad-4df0-870f-a4073d4fe9d0",
   "metadata": {},
   "source": [
    "### Composition\n",
    "Created geojson file contains field \"ground_truth\" with all values set to -1. The values must be assigned manually with the value showing the truth for this class. Useful will be composite image with which you can easily make RGB representations. We will use \"draw_composition\" function with parameters:\n",
    "1. output_file - the name of file which will be saved to directory \"compositions\"\n",
    "2. bbox - bounding box of part which we want to extract. Indicate None to take whole image. Defaults to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5800cbfe-5c30-4874-8fbe-cdb22c0ba1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in found:\n",
    "    if 'L2A' in el.name:\n",
    "        el.draw_composition(\n",
    "            \"Swinoujscie\",\n",
    "            Bbox(\n",
    "                53.82,\n",
    "                14.0324,\n",
    "                54.1,\n",
    "                14.25,\n",
    "                \"EPSG:4326\"\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb880b0-ba75-4f59-8ca9-b1e4a2ab63bb",
   "metadata": {},
   "source": [
    "### Import test dataset\n",
    "After fulfilling of \"ground_truth\" column, we can load test dataset using PointDataset class. The constructor has parameters like VectorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d80500-1bf9-40f6-836b-75aa7d90dd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             y         x  value  ground_truth                        geometry\n",
      "0    5979825.0  447325.0    0.0           0.0  POINT (447325.000 5979825.000)\n",
      "1    5968685.0  439655.0    0.0           0.0  POINT (439655.000 5968685.000)\n",
      "2    5978095.0  436515.0    0.0           0.0  POINT (436515.000 5978095.000)\n",
      "3    5992845.0  445875.0    0.0           0.0  POINT (445875.000 5992845.000)\n",
      "4    5966965.0  450045.0    0.0           0.0  POINT (450045.000 5966965.000)\n",
      "..         ...       ...    ...           ...                             ...\n",
      "495  5979565.0  443365.0    4.0           4.0  POINT (443365.000 5979565.000)\n",
      "496  5971375.0  445095.0    4.0           4.0  POINT (445095.000 5971375.000)\n",
      "497  5978425.0  442315.0    4.0           4.0  POINT (442315.000 5978425.000)\n",
      "498  5973205.0  442765.0    4.0           4.0  POINT (442765.000 5973205.000)\n",
      "499  5982025.0  440295.0    4.0           4.0  POINT (440295.000 5982025.000)\n",
      "\n",
      "[500 rows x 5 columns]\n",
      "['T33UVV_20230910T100601_B02_10m.jp2', 'T33UVV_20230910T100601_B03_10m.jp2', 'T33UVV_20230910T100601_B04_10m.jp2', 'T33UVV_20230910T100601_B05_20m.jp2', 'T33UVV_20230910T100601_B06_20m.jp2', 'T33UVV_20230910T100601_B07_20m.jp2', 'T33UVV_20230910T100601_B08_10m.jp2', 'T33UVV_20230910T100601_B11_20m.jp2', 'T33UVV_20230910T100601_B12_20m.jp2', 'T33UVV_20230910T100601_B8A_20m.jp2']\n",
      "{0, 1, 2, 3, 4}\n",
      "(500,)\n",
      "(500, 10, 1, 1)\n",
      "(500, 10)\n"
     ]
    }
   ],
   "source": [
    "from dataset import PointDataset\n",
    "from config import workspace\n",
    "import os\n",
    "\n",
    "data = gpd.read_file(os.path.join(workspace, 'test_datasets', 'Swinoujscie.geojson')\n",
    "print(data)\n",
    "\n",
    "\n",
    "\n",
    "dataset = PointDataset(\n",
    "        dataset_name=\"swinoujscie1\",\n",
    "        label_source=data,\n",
    "        class_column=\"ground_truth\",\n",
    "        sentinel2image=[load_image(\"S2A_MSIL2A_20230910T100601_N0509_R022_T33UVV_20230910T161500.SAFE\")],\n",
    "        apply_cloud_mask=[8, 4],\n",
    "        window_size=0,\n",
    "        is_conv=False,\n",
    "        apply_rotations_and_reflections=False\n",
    "    )\n",
    "dataset.save_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f669a3-222f-4d74-aa3c-6a497658691e",
   "metadata": {},
   "source": [
    "### Classify test dataset\n",
    "Now we have test dataset imported, we can use it to evaluate model, for what we will use \"classify_dataset\" functions with parameters:\n",
    "1. dataset_name - name of the dataset\n",
    "2. report_name - name of docx report saved to \"reports/classifying\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac00c79-bf17-4f37-b089-e5cb19204edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.722, 0.6525)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.classify_dataset(\"swinoujscie1\", \"rfc150_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4261c234-545e-4062-b98a-f10040b99e68",
   "metadata": {},
   "source": [
    "So we've made the example workflow. Thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyterenv)",
   "language": "python",
   "name": "jupyterenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
